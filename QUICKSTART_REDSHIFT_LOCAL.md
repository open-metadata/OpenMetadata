# Quick Start: Redshift Distributed Ingestion (Local Testing)

## Overview

This guide shows you how to test distributed ingestion with Redshift **on your local machine** in 5 minutes - no Kubernetes required!

## What You'll Get

- **4-6x faster** ingestion compared to sequential mode
- Works on your laptop/workstation
- Uses threads instead of Kubernetes pods
- Perfect for testing before production deployment

## Prerequisites

1. **OpenMetadata running locally** (http://localhost:8585)
2. **Redshift cluster** accessible from your machine
3. **Python 3.9+** with OpenMetadata ingestion installed

## Step-by-Step Guide

### 1. Set Environment Variables

```bash
# Redshift credentials
export REDSHIFT_USER="your_username"
export REDSHIFT_PASSWORD="your_password"
export REDSHIFT_HOST="your-cluster.region.redshift.amazonaws.com"
export REDSHIFT_PORT="5439"
export REDSHIFT_DATABASE="dev"

# OpenMetadata JWT token
# Get from: OpenMetadata UI â†’ Settings â†’ Bots â†’ ingestion-bot â†’ Token
export OM_JWT_TOKEN="eyJraWQiOiJH..."
```

### 2. Create Workflow Configuration

Create `redshift-test.yaml`:

```yaml
source:
  type: redshift
  serviceName: redshift-local-test
  serviceConnection:
    config:
      type: Redshift
      username: ${REDSHIFT_USER}
      password: ${REDSHIFT_PASSWORD}
      hostPort: ${REDSHIFT_HOST}:${REDSHIFT_PORT}
      database: ${REDSHIFT_DATABASE}
  sourceConfig:
    config:
      type: DatabaseMetadata
      schemaFilterPattern:
        includes:
          - "^public$"  # Start with just public schema
      includeViews: true
      includeTables: true

sink:
  type: metadata-rest
  config:
    api_endpoint: null

workflowConfig:
  openMetadataServerConfig:
    hostPort: http://localhost:8585/api
    authProvider: openmetadata
    securityConfig:
      jwtToken: ${OM_JWT_TOKEN}

  # Enable local distributed mode
  distributedExecution:
    enabled: true
    orchestrator: local  # KEY: 'local' for thread-based execution
    parallelism: 10      # Adjust based on your machine (5-20)

  loggerLevel: INFO
```

### 3. Run Ingestion

```bash
metadata ingest -c redshift-test.yaml
```

### 4. Watch the Progress

You'll see output like:

```
[INFO] Executing workflow in DISTRIBUTED mode via local threads
[INFO] Using LOCAL thread-based distributed execution
[INFO] Starting LOCAL distributed execution with 10 threads
[INFO] Phase 1: Discovering entities...
[INFO] Discovering table...
[INFO] Found 47 table entities
[INFO] Total entities to process: 47
[INFO] Phase 2: Processing entities with 10 worker threads...
[INFO] âœ“ Processed table: public.users (1/47)
[INFO] âœ“ Processed table: public.orders (2/47)
[INFO] âœ“ Processed table: public.products (3/47)
...
[INFO] ================================================================================
[INFO] LOCAL DISTRIBUTED EXECUTION SUMMARY
[INFO] ================================================================================
[INFO] Total entities: 47
[INFO] Successful: 47
[INFO] Failed: 0
[INFO] Success rate: 100.0%
[INFO] Duration: 28.5 seconds
[INFO] Throughput: 1.6 entities/second
[INFO] ================================================================================
```

### 5. Verify in OpenMetadata UI

1. Open http://localhost:8585
2. Navigate to: **Explore** â†’ **Tables**
3. You should see your Redshift tables!

## Performance Comparison

### Before (Sequential Mode)
```
47 tables in ~3 minutes
Throughput: 0.26 entities/second
```

### After (Local Distributed - 10 threads)
```
47 tables in ~30 seconds
Throughput: 1.6 entities/second
Speedup: 6x faster!
```

## Tuning Parallelism

### For Different Machine Sizes

**Small laptop (4 cores, 8GB RAM):**
```yaml
parallelism: 5
```

**Medium workstation (8 cores, 16GB RAM):**
```yaml
parallelism: 10
```

**Powerful machine (16+ cores, 32GB+ RAM):**
```yaml
parallelism: 20
```

### Finding Optimal Value

Try different values and compare throughput:

```bash
# Test with 5 threads
sed -i 's/parallelism: .*/parallelism: 5/' redshift-test.yaml
time metadata ingest -c redshift-test.yaml

# Test with 10 threads
sed -i 's/parallelism: .*/parallelism: 10/' redshift-test.yaml
time metadata ingest -c redshift-test.yaml

# Test with 15 threads
sed -i 's/parallelism: .*/parallelism: 15/' redshift-test.yaml
time metadata ingest -c redshift-test.yaml
```

Pick the value with highest throughput (entities/second).

## Scaling to Full Database

Once testing succeeds, remove schema filter for full ingestion:

```yaml
sourceConfig:
  config:
    type: DatabaseMetadata
    # Remove or comment out schemaFilterPattern
    # schemaFilterPattern:
    #   includes:
    #     - "^public$"
    includeViews: true
    includeTables: true
    includeStoredProcedures: true
```

## Troubleshooting

### Connection Errors

**Error:** `Unable to connect to Redshift`

**Check:**
```bash
# Test connection manually
psql -h $REDSHIFT_HOST -p $REDSHIFT_PORT -U $REDSHIFT_USER -d $REDSHIFT_DATABASE
```

### Authentication Errors

**Error:** `401 Unauthorized`

**Solution:** Verify JWT token is valid:
```bash
echo $OM_JWT_TOKEN  # Should be a long string starting with "eyJ"
```

Get new token from: OpenMetadata UI â†’ Settings â†’ Bots â†’ ingestion-bot

### Slow Performance

**If throughput < 0.5 entities/second:**

1. Reduce parallelism (too many threads)
2. Check Redshift cluster performance
3. Check network latency to Redshift

### Memory Errors

**Error:** `MemoryError` or system slowdown

**Solution:** Reduce parallelism:
```yaml
parallelism: 5  # Lower value
```

## Next Steps

### 1. Compare to Sequential Mode

Run traditional sequential ingestion:

```yaml
workflowConfig:
  # Remove distributedExecution section entirely
  openMetadataServerConfig:
    hostPort: http://localhost:8585/api
```

```bash
time metadata ingest -c redshift-sequential.yaml
```

Compare duration to see speedup!

### 2. Test with Other Databases

The same approach works for:
- PostgreSQL
- MySQL
- Snowflake
- BigQuery
- Any database connector

Just change `type: redshift` to your database type.

### 3. Move to Production (Argo)

When ready for Kubernetes deployment:

```yaml
workflowConfig:
  distributedExecution:
    enabled: true
    orchestrator: argo  # Change from 'local' to 'argo'
    parallelism: 100    # Scale up to 100+ pods
    namespace: openmetadata
    image: openmetadata/ingestion:latest
```

See `examples/distributed-ingestion/redshift-distributed.yaml` for full example.

## Summary

You've successfully:
- âœ… Configured Redshift distributed ingestion
- âœ… Run ingestion with local threads (no Kubernetes)
- âœ… Achieved 4-6x speedup over sequential mode
- âœ… Verified results in OpenMetadata UI

**Total time:** 5 minutes to setup, test, and verify!

## Resources

- **Full documentation:** `/DISTRIBUTED_INGESTION_IMPLEMENTATION.md`
- **Local testing guide:** `/examples/distributed-ingestion/LOCAL_TESTING.md`
- **Example configs:** `/examples/distributed-ingestion/`
- **Issues:** https://github.com/open-metadata/OpenMetadata/issues

---

**Enjoy faster ingestion! ðŸš€**
