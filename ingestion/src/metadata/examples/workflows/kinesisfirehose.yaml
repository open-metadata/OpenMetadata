# AWS Kinesis Firehose Workflow Configuration
#
# This workflow extracts metadata from AWS Kinesis Firehose delivery streams
# and creates lineage between sources (DynamoDB) and destinations
# (S3, Redshift, OpenSearch, Snowflake)
#
# Supported Features:
# - Pipeline metadata extraction
# - Entity-level lineage (DynamoDB → Firehose → Destination)
# - Column-level lineage (automatic column matching by name)
#
# Required IAM Permissions:
# - firehose:ListDeliveryStreams
# - firehose:DescribeDeliveryStream

source:
  type: kinesisfirehose
  serviceName: aws_firehose_production
  serviceConnection:
    config:
      type: KinesisFirehose
      awsConfig:
        # AWS Region where Firehose delivery streams are located
        awsRegion: us-east-1

        # Authentication Option 1: Access Key & Secret (for development/testing)
        awsAccessKeyId: AKIAIOSFODNN7EXAMPLE
        awsSecretAccessKey: wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY

        # Authentication Option 2: Temporary Session Token (for STS)
        # awsSessionToken: "temporary-session-token"

        # Authentication Option 3: AWS Profile (uses ~/.aws/credentials)
        # profileName: "openmetadata-profile"

        # Authentication Option 4: Assume Role (for cross-account access)
        # assumeRoleArn: "arn:aws:iam::123456789012:role/OpenMetadataFirehoseRole"
        # assumeRoleSessionName: "OpenMetadataFirehoseSession"
        # assumeRoleSourceIdentity: "arn:aws:iam::987654321098:user/admin"

        # Optional: Custom endpoint for LocalStack or VPC endpoints
        # endPointURL: "https://firehose.us-east-1.amazonaws.com/"

  sourceConfig:
    config:
      type: PipelineMetadata

      # Optional: Filter delivery streams by name pattern
      # pipelineFilterPattern:
      #   includes:
      #     - "prod-.*"
      #     - "cdc-.*"
      #   excludes:
      #     - "test-.*"
      #     - "dev-.*"

      # Optional: Enable lineage extraction (default: true)
      # includeLineage: true

      # Optional: Mark deleted pipelines (delivery streams no longer in AWS)
      # markDeletedPipelines: true

sink:
  type: metadata-rest
  config: {}

workflowConfig:
  # Optional: Set log level (DEBUG, INFO, WARN, ERROR)
  # loggerLevel: INFO

  openMetadataServerConfig:
    hostPort: "http://localhost:8585/api"
    authProvider: openmetadata
    securityConfig:
      jwtToken: "eyJraWQiOiJHYjM4OWEtOWY3Ni1nZGpzLWE5MmotMDI0MmJrOTQzNTYiLCJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9.eyJzdWIiOiJhZG1pbiIsImlzQm90IjpmYWxzZSwiaXNzIjoib3Blbi1tZXRhZGF0YS5vcmciLCJpYXQiOjE2NjM5Mzg0NjIsImVtYWlsIjoiYWRtaW5Ab3Blbm1ldGFkYXRhLm9yZyJ9.tS8um_5DKu7HgzGBzS1VTA5uUjKWOCU0B_j08WXBiEC0mr0zNREkqVfwFDD-d24HlNEbrqioLsBuFRiwIWKc1m_ZlVQbG7P36RUxhuv2vbSp80FKyNM-Tj93FDzq91jsyNmsQhyNv_fNr3TXfzzSPjHt8Go0FMMP66weoKMgW2PbXlhVKwEuXUHyakLLzewm9UMeQaEiRzhiTMU3UkLXcKbYEJJvfNFcLwSl9W8JCO_l0Yj3ud-qt_nQYEZwqW6u5nfdQllN133iikV4fM5QZsMCnm8Rq1mvLR0y9bmJiD7fwM1tmJ791TUWqmKaTnP49U493VanKpUAfzIiOiIbhg"

# Lineage Support:
#
# This connector automatically creates lineage when it finds:
#
# 1. DynamoDB → Firehose → S3
#    - Source: DynamoDB table (from KinesisStreamSourceConfiguration)
#    - Destination: S3 container (from S3DestinationDescription)
#
# 2. DynamoDB → Firehose → Redshift
#    - Source: DynamoDB table
#    - Destination: Redshift table (from RedshiftDestinationDescription)
#
# 3. DynamoDB → Firehose → OpenSearch
#    - Source: DynamoDB table
#    - Destination: OpenSearch index (from AmazonopensearchserviceDestinationDescription)
#
# 4. DynamoDB → Firehose → Snowflake
#    - Source: DynamoDB table
#    - Destination: Snowflake table (from SnowflakeDestinationDescription)
#
# Note: Both source and destination entities must exist in OpenMetadata
# for lineage to be created. Column-level lineage is automatically
# generated by matching column names (case-insensitive).
